# 深度神经网络是否夸张地过拟合了
> 作者｜Lilian Weng
> 译者｜姚佳灵
> 编辑｜Debra
- [中文原文](https://mp.weixin.qq.com/s?__biz=MzU1NDA4NjU2MA==&mid=2247496352&idx=2&sn=e965b288799f07591e8c00e76ca149a7&chksm=fbea4b6fcc9dc279105733036f3e9efd76e17aeb742cbe3d97f18352ba1dcc47dfdac3faba9d&scene=0&xtrack=1#rd)
- [英文原文](https://lilianweng.github.io/lil-log/2019/03/14/are-deep-neural-networks-dramatically-overfitted.html)
#### 导读：
> 本文讨论了一些关于深度学习模型的泛化和复杂性度量的论文，希望能帮助读者理解深度神经网络（DNN）能够泛化的原因。
如果你和我一样，不明白为什么深度神经网络可以泛化到样本外数据点，而过拟合不严重，那么请看本文。

如果你和我一样，带着传统机器学习的经验进入深度学习领域，我们可能常常会对这个问题感到疑惑：既然典型的深度神经网络有这么多参数，训练误差能够轻松地做到完美，那么，它就应该受到大量过拟合的困扰。如何才能泛化到样本外数据点呢？
在理解为什么神经网络能够泛化的过程中，我想起了一篇关于系统生物学的有趣论文[《生物学家会修收音机吗》](https://bml.bioe.uic.edu/BML/Stuff/Stuff_files/biologist%20fix%20radio.pdf)
如果生物学家打算像生物系统中的工作那样去修收音机，生活可能就很艰难了。因为无线电系统的整个机制还没有完全揭示出来，所以寻找小的局部功能也许会得到一些线索，但是，这很难呈现系统中的所有交互情况，更不用说整个工作流程了。无论我们是否认为这和深度学习相关，那篇文章读起来都会很有趣。
我想在本文中讨论一些关于深度学习模型的泛化和复杂性度量的论文。希望能帮助读者理解深度神经网络（DNN）能够泛化的原因。

**<a href="#压缩和模型选择的经典定理（Classic Theorems on Compression and Model Selection）">压缩和模型选择的经典定理（Classic Theorems on Compression and Model Selection）</a>**

- <a href="#奥卡姆剃刀（Occam’s Razor）">奥卡姆剃刀（Occam’s Razor）</a>
- <a href="#最小描述长度原理（ Minimum Description Length principle）">最小描述长度原理（ Minimum Description Length principle）</a>
- <a href="#Kolmogorov 复杂性（Kolmogorov Complexity）">Kolmogorov 复杂性（Kolmogorov Complexity）</a>
- <a href="#Solomonoff 的归纳推理理论（Solomonoff’s Inference Theory）">Solomonoff 的归纳推理理论（Solomonoff’s Inference Theory）</a>

**<a href="#深度学习模型的表现力（Expressive Power of DL Models）">深度学习模型的表现力（Expressive Power of DL Models）</a>**

- <a href="#通用逼近定理（ Universal Approximation Theorem）">通用逼近定理（ Universal Approximation Theorem）</a>
- <a href="#证明：双层神经网络的有限样本表达性（Finite Sample Expressivity of Two-layer NN）">证明：双层神经网络的有限样本表达性（Finite Sample Expressivity of Two-layer NN）</a>
- <a href="#深度神经网络可以学习随机噪声">深度神经网络可以学习随机噪声</a>

**<a href="#深度学习模型是否夸张地过拟合了？">深度学习模型是否夸张地过拟合了？</a>**

- <a href="#深度学习的现代风险曲线">深度学习的现代风险曲线</a>
- <a href="#正则化不是泛化的关键">正则化不是泛化的关键</a>
- <a href="#内在维度">内在维度</a>
- <a href="#异构层稳健性">异构层稳健性</a>

**<a href="#实验">实验</a>**

**<a href="#参考文献">参考文献</a>**

## 压缩和模型选择的经典定理（Classic Theorems on Compression and Model Selection）
假设我们有一个分类问题和一个数据集，我们可以开发很多模型来解决这个分类问题，从拟合简单的线性回归到在磁盘空间中存储整个数据集。哪个更好呢？如果我们只关心训练数据的准确性（特别是考虑到测试数据可能未知），存储方法似乎是最好的，但是，听起来不太对。

在这个场景中，当我们要决定一个好的模型应当具有哪种属性时，有很多经典理论可以指导我们。

#### 奥卡姆剃刀
奥卡姆剃刀 是一种用于解决问题的非正式原则，由 Ockham 的 William 在 14 世纪提出：
> “简单的解决方案比复杂的方案更可能是正确的。”

当我们面对多个候选的潜在理论，必须挑出一个来解释世界时，这个说法极其有用。对于一个问题，有太多不必要的假设似乎是合理地，但是很难泛化到其他复杂的问题，或者最终归结到了宇宙的基本原则上。
想想看，人们花了数百年的时间才搞明白，天空在白天看起来是蓝色的，而太阳下山时是红色的原因是相同的[瑞利散射](https://en.wikipedia.org/wiki/Rayleigh_scattering)，尽管这两个现象看起来极其不同。对于它们，人们肯定分别提出了很多其他解释，但是，统一且简单的版本最终胜出。
#### 最小描述长度原理
奥卡姆剃刀原理可以类似地应用于机器学习模型。这个概念的形式化版本被称为最小描述长度（Minimum Description Length，简称 MDL）原理，用于比较竞争模型 / 解释给定的观察到的数据。
>“理解就是压缩。”

MDL 中的基本思想是把学习看作数据压缩。通过压缩数据，我们需要发现数据中的规律或模式，这些规律或模式具有很高的潜力以泛化到尚未看到的样本中。信息瓶颈理论认为，首先是训练深度神经网络，通过最小泛化误差表示数据，然后学习通过修剪噪声来压缩这种表示。
与此同时，MDL 把模型描述看作是压缩交付的一部分，因此，模型不能任意大。

MDL 原理的两部分版本表示为：设，……是个模型列表，该模型列表可以解释数据集 D。它们中最好的假设应该是把总和最小化的那个：
![](https://mmbiz.qpic.cn/mmbiz_png/ZBjVrHIdkOnRd0K3CyyiaPtnLQTocWU697l0kMeoggmAgPKQ24oOpn2oTz7CP1wI49bxibibicvgAO0eZZsGfpWuiaw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)














