{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文语言处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和拉丁语系不同，亚洲语言是不用空格分开每个有意义的词的。而当我们进行自然语言处理的时候，大部分情况下，词汇是我们对句子和文章理解的基础，因此需要一个工具去把完整的文本中分解成粒度更细的词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键词提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TF-IDF 算法的关键词抽取\n",
    "\n",
    "``` \n",
    "import jieba.analyse\n",
    " × jieba.analyse.extract_tags(sentence, topK=20, withWeight=False, allowPOS=())\n",
    "        × sentence 为待提取的文本\n",
    "        × topK 为返回几个 TF/IDF 权重最大的关键词，默认值为 20\n",
    "        × withWeight 为是否一并返回关键词权重值，默认值为 False\n",
    "        × allowPOS 仅包括指定词性的词，默认值为空，即不筛选\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.547 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户  2016  互联网  手机  平台  人工智能  百度  2017  智能  技术  数据  360  服务  直播  产品  企业  安全  视频  移动  应用  网络  行业  游戏  机器人  电商  内容  中国  领域  通过  发展\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as analyse\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"technology_news.csv\", encoding='utf-8')\n",
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()\n",
    "content = \"\".join(lines)\n",
    "print(\"  \".join(analyse.extract_tags(content, topK=30, withWeight=False, allowPOS=())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "航母  训练  海军  中国  官兵  部队  编队  作战  10  任务  美国  导弹  能力  20  2016  军事  无人机  装备  进行  记者  我们  军队  安全  保障  12  战略  军人  日本  南海  战机\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as analyse\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"military_news.csv\", encoding='utf-8')\n",
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()\n",
    "content = \"\".join(lines)\n",
    "print(\"  \".join(analyse.extract_tags(content, topK=30, withWeight=False, allowPOS=())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于 TextRank 算法的关键词抽取\n",
    "\n",
    "> jieba.analyse.textrank(sentence, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v')) 直接使用，接口相同，注意默认过滤词性。\n",
    "\n",
    "> jieba.analyse.TextRank() 新建自定义 TextRank 实例\n",
    "\n",
    "算法论文：[<i class=\"fa fa-external-link-square\" aria-hidden=\"true\"> TextRank: Bringing Order into Texts</i>](http://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf)\n",
    "\n",
    "基本思想:\n",
    "\n",
    "- 将待抽取关键词的文本进行分词\n",
    "- 以固定窗口大小(默认为5，通过span属性调整)，词之间的共现关系，构建图\n",
    "- 计算图中节点的PageRank，注意是无向带权图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国  海军  训练  美国  部队  进行  官兵  航母  作战  任务  能力  军事  发展  工作  国家  问题  建设  导弹  编队  记者\n",
      "---------------------我是分割线----------------\n",
      "中国  海军  美国  部队  官兵  航母  军事  国家  任务  能力  导弹  技术  问题  日本  军队  编队  装备  系统  记者  战略\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as analyse\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"military_news.csv\", encoding='utf-8')\n",
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()\n",
    "content = \"\".join(lines)\n",
    "\n",
    "print(\"  \".join(analyse.textrank(content, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))))\n",
    "print(\"---------------------我是分割线----------------\")\n",
    "print(\"  \".join(analyse.textrank(content, topK=20, withWeight=False, allowPOS=('ns', 'n'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA主题模型\n",
    "\n",
    "\n",
    "下面用LDA主题模型建模，看看这些新闻主要在说哪些topic。\n",
    "\n",
    "首先我们要把文本内容处理成固定的格式，一个包含句子的list，list中每个元素是分词后的词list。类似下面这个样子。\n",
    "\n",
    "[[第，一，条，新闻，在，这里],[第，二，条，新闻，在，这里],[这，是，在，做， 什么],...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords=pd.read_csv(\"stopwords.txt\",index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stopwords=stopwords['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换成合适的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"technology_news.csv\", encoding='utf-8')\n",
    "df = df.dropna()\n",
    "lines=df.content.values.tolist()\n",
    "\n",
    "sentences=[]\n",
    "for line in lines:\n",
    "    try:\n",
    "        segs=jieba.lcut(line)\n",
    "        segs = [x for x in segs if len(x)>1]\n",
    "        segs = [x for x in segs if x not in stopwords]\n",
    "        sentences.append(segs)\n",
    "    except Exception as e:\n",
    "        print(line)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次\n",
      "商汤\n",
      "带来\n",
      "黄仁勋\n",
      "展示\n",
      "遥相呼应\n",
      "SenseFace\n",
      "人脸\n",
      "布控\n",
      "系统\n",
      "千万级\n",
      "人员\n",
      "库中\n",
      "300ms\n",
      "识别\n",
      "瞬间\n",
      "锁定目标\n",
      "功耗\n",
      "十几\n",
      "当属\n",
      "人脸\n",
      "布控\n",
      "一大\n",
      "科技\n"
     ]
    }
   ],
   "source": [
    "for word in sentences[5]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(sentences)\n",
    "corpus = [dictionary.doc2bow(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, 1),\n",
       " (39, 1),\n",
       " (61, 1),\n",
       " (68, 1),\n",
       " (78, 1),\n",
       " (82, 1),\n",
       " (91, 1),\n",
       " (92, 1),\n",
       " (103, 1),\n",
       " (104, 2),\n",
       " (105, 2),\n",
       " (124, 1),\n",
       " (129, 1),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 1),\n",
       " (136, 1),\n",
       " (137, 1),\n",
       " (138, 1)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们查一下第3号分类，其中最常出现的单词是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043*\"电视\" + 0.035*\"乐视\" + 0.017*\"充电\" + 0.015*\"比特\" + 0.014*\"量子\"\n"
     ]
    }
   ],
   "source": [
    "print(lda.print_topic(3, topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把所有的主题打印出来看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048*\"手机\" + 0.020*\"产品\" + 0.020*\"联想\" + 0.017*\"汽车\" + 0.015*\"品牌\" + 0.015*\"市场\" + 0.013*\"中国\" + 0.010*\"360\"\n",
      "0.037*\"公司\" + 0.032*\"中国\" + 0.020*\"科技\" + 0.020*\"市场\" + 0.015*\"业务\" + 0.015*\"创业\" + 0.014*\"投资\" + 0.012*\"企业\"\n",
      "0.020*\"青年\" + 0.018*\"商家\" + 0.018*\"处理器\" + 0.018*\"糯米\" + 0.018*\"赋能\" + 0.016*\"营销\" + 0.016*\"供应链\" + 0.015*\"零售\"\n",
      "0.043*\"电视\" + 0.035*\"乐视\" + 0.017*\"充电\" + 0.015*\"比特\" + 0.014*\"量子\" + 0.013*\"显示\" + 0.011*\"电子\" + 0.011*\"技术\"\n",
      "0.122*\"游戏\" + 0.026*\"腾讯\" + 0.018*\"IP\" + 0.018*\"玩家\" + 0.015*\"金立\" + 0.014*\"赛事\" + 0.014*\"无人机\" + 0.013*\"动漫\"\n",
      "0.031*\"网络安全\" + 0.027*\"攻击\" + 0.023*\"网络\" + 0.021*\"信息\" + 0.020*\"漏洞\" + 0.018*\"360\" + 0.016*\"诈骗\" + 0.015*\"手机\"\n",
      "0.030*\"增长\" + 0.022*\"国美\" + 0.015*\"同比\" + 0.014*\"市场\" + 0.013*\"销售\" + 0.013*\"网秦\" + 0.013*\"消费者\" + 0.012*\"文件\"\n",
      "0.054*\"数据\" + 0.025*\"服务\" + 0.014*\"企业\" + 0.014*\"提供\" + 0.013*\"平台\" + 0.010*\"互联网\" + 0.010*\"能力\" + 0.010*\"体系\"\n",
      "0.028*\"用户\" + 0.023*\"互联网\" + 0.018*\"网络\" + 0.015*\"平台\" + 0.014*\"流量\" + 0.010*\"运营商\" + 0.009*\"服务\" + 0.009*\"模式\"\n",
      "0.058*\"病毒\" + 0.048*\"勒索\" + 0.027*\"京东\" + 0.025*\"亿元\" + 0.021*\"收入\" + 0.019*\"增长\" + 0.014*\"学院\" + 0.013*\"加密\"\n",
      "0.031*\"发展\" + 0.021*\"企业\" + 0.018*\"合作\" + 0.016*\"产业\" + 0.015*\"中国\" + 0.015*\"行业\" + 0.015*\"战略\" + 0.014*\"互联网\"\n",
      "0.053*\"智能\" + 0.031*\"机器人\" + 0.021*\"工作\" + 0.018*\"人工智能\" + 0.015*\"技术\" + 0.014*\"办公\" + 0.012*\"人类\" + 0.012*\"科技\"\n",
      "0.015*\"一路\" + 0.014*\"一带\" + 0.014*\"外卖\" + 0.011*\"蓝色\" + 0.010*\"全国\" + 0.010*\"采访\" + 0.009*\"接受\" + 0.009*\"上海\"\n",
      "0.031*\"手机\" + 0.031*\"APP\" + 0.023*\"用户\" + 0.017*\"单车\" + 0.015*\"微信\" + 0.014*\"视频\" + 0.012*\"数据\" + 0.011*\"榜单\"\n",
      "0.033*\"城市\" + 0.029*\"智慧\" + 0.016*\"电商\" + 0.014*\"物流\" + 0.013*\"技术\" + 0.013*\"建设\" + 0.011*\"发展\" + 0.010*\"联网\"\n",
      "0.035*\"内容\" + 0.032*\"视频\" + 0.030*\"直播\" + 0.026*\"用户\" + 0.020*\"平台\" + 0.013*\"广告\" + 0.011*\"百度\" + 0.009*\"孩子\"\n",
      "0.014*\"工具\" + 0.011*\"系统\" + 0.011*\"超级\" + 0.009*\"年轻人\" + 0.008*\"画面\" + 0.008*\"产品\" + 0.008*\"社区\" + 0.007*\"分享\"\n",
      "0.037*\"技术\" + 0.030*\"人工智能\" + 0.030*\"百度\" + 0.016*\"用户\" + 0.013*\"产品\" + 0.010*\"学习\" + 0.009*\"领域\" + 0.008*\"未来\"\n",
      "0.028*\"永恒\" + 0.023*\"感染\" + 0.018*\"论坛\" + 0.013*\"现场\" + 0.012*\"服务器\" + 0.010*\"棋牌\" + 0.009*\"节目\" + 0.009*\"就业\"\n",
      "0.040*\"小米\" + 0.024*\"旅游\" + 0.019*\"携程\" + 0.015*\"Windows\" + 0.013*\"搜狗\" + 0.011*\"输入法\" + 0.010*\"皮肤\" + 0.010*\"旅行\"\n"
     ]
    }
   ],
   "source": [
    "for topic in lda.print_topics(num_topics=20, num_words=8):\n",
    "    print(topic[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以对新加入的文本，进行简单主题分类：\n",
    "\n",
    "- lda.get_document_topics(bow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
